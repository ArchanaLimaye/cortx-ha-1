#!/bin/bash

set -eu -o pipefail

HA_PATH="<HA_PATH>"

init() {
    echo "Setup Decision maker"
    lnode=$(grep left-node $ARGS | awk '{print $2}')
    rnode=$(grep right-node $ARGS | awk '{print $2}')
    host1=$(salt-call pillar.get cluster --output=json | jq '.local."srvnode-1".hostname' | sed  s/\"//g )
    host2=$(salt-call pillar.get cluster --output=json | jq '.local."srvnode-2".hostname' | sed  s/\"//g )
    uuid1=$(salt "*" grains.get node_id --output=json | jq '.["srvnode-1"]')
    uuid2=$(salt "*" grains.get node_id --output=json | jq '.["srvnode-2"]')

    echo "Reading cluster.sls"
    node1_data_nw=$(salt-call --local pillar.get cluster:srvnode-1 --output=json | jq '.["local"].network["data_nw"].iface')
    node1_mgmt_nw=$(salt-call --local pillar.get cluster:srvnode-1 --output=json | jq '.["local"].network["mgmt_nw"].iface')
    node2_data_nw=$(salt-call --local pillar.get cluster:srvnode-2 --output=json | jq '.["local"].network["data_nw"].iface')
    node2_mgmt_nw=$(salt-call --local pillar.get cluster:srvnode-2 --output=json | jq '.["local"].network["mgmt_nw"].iface')

    decision_monitor_conf=${HA_PATH}/conf/decision_monitor_conf.json
    cp -rf $decision_monitor_conf /tmp/decision_monitor_conf1.json
    cp -rf $decision_monitor_conf /tmp/decision_monitor_conf2.json

    sed -i -e "s|<LOCAL>|${host1}|g" \
        -e "s|<HOST1>|${host1}|g" \
        -e "s|<HOST2>|${host2}|g" /tmp/decision_monitor_conf1.json
    sed -i -e "s|\"<UUID1>\"|${uuid1//$'\n'}|g" -e "s|null||g" /tmp/decision_monitor_conf1.json
    sed -i -e "s|\"<UUID2>\"|${uuid2//$'\n'}|g" -e "s|null||g" /tmp/decision_monitor_conf1.json

    sed -i -e "s|<LOCAL>|${host2}|g" \
        -e "s|<HOST1>|${host1}|g" \
        -e "s|<HOST2>|${host2}|g" /tmp/decision_monitor_conf2.json
    sed -i -e "s|\"<UUID1>\"|${uuid1//$'\n'}|g" -e "s|null||g" /tmp/decision_monitor_conf2.json
    sed -i -e "s|\"<UUID2>\"|${uuid2//$'\n'}|g" -e "s|null||g" /tmp/decision_monitor_conf2.json

    sed -i -e "s|\"<N1_DATA_IFACE>\"|${node1_data_nw//$'\n'/}|g" \
        -e "s|\"<N1_MGMT_IFACE>\"|${node1_mgmt_nw//$'\n'/}|g" \
        -e "s|\"<N2_DATA_IFACE>\"|${node2_data_nw//$'\n'/}|g" \
        -e "s|\"<N2_MGMT_IFACE>\"|${node2_mgmt_nw//$'\n'/}|g" /tmp/decision_monitor_conf1.json

    sed -i -e "s|\"<N1_DATA_IFACE>\"|${node1_data_nw//$'\n'/}|g" \
        -e "s|\"<N1_MGMT_IFACE>\"|${node1_mgmt_nw//$'\n'/}|g" \
        -e "s|\"<N2_DATA_IFACE>\"|${node2_data_nw//$'\n'/}|g" \
        -e "s|\"<N2_MGMT_IFACE>\"|${node2_mgmt_nw//$'\n'/}|g" /tmp/decision_monitor_conf2.json

    cp -rf /tmp/decision_monitor_conf1.json /etc/cortx/ha/decision_monitor_conf.json
    scp -r /tmp/decision_monitor_conf2.json $rnode:/etc/cortx/ha/decision_monitor_conf.json
    rm -rf /tmp/decision_monitor_conf1.json /tmp/decision_monitor_conf2.json

    pcs cluster cib hw_cfg
    pcs -f hw_cfg resource create io_path_health_c1 ocf:seagate:hw_comp_ra path='io' filename='io_path_health_c1' op monitor timeout=30s interval=30s
    pcs -f hw_cfg resource create io_path_health_c2 ocf:seagate:hw_comp_ra path='io' filename='io_path_health_c2' op monitor timeout=30s interval=30s
    pcs -f hw_cfg resource create mgmt_path_health_c1 ocf:seagate:hw_comp_ra path='mgmt' filename='mgmt_path_health_c1' op monitor timeout=30s interval=30s

    pcs -f hw_cfg resource group add c1 io_path_health_c1
    pcs -f hw_cfg resource group add c2 io_path_health_c2
    pcs -f hw_cfg resource group add csm-kibana mgmt_path_health_c1

    pcs -f hw_cfg constraint order set consul-c1 io_path_health_c1
    pcs -f hw_cfg constraint order set consul-c2 io_path_health_c2
    pcs -f hw_cfg constraint order set consul-c1 mgmt_path_health_c1
    pcs cluster cib-push hw_cfg

    pcs cluster cib iem_cfg
    pcs -f iem_cfg resource create node_iem_mero_c1 ocf:seagate:iem_comp_ra path='node_iem_mero' filename='node_iem_mero_c1' node=$lnode op monitor timeout=30s interval=30s
    pcs -f iem_cfg resource create node_iem_mero_c2 ocf:seagate:iem_comp_ra path='node_iem_mero' filename='node_iem_mero_c2' node=$rnode op monitor timeout=30s interval=30s
    pcs -f iem_cfg resource group add c1 node_iem_mero_c1
    pcs -f iem_cfg resource group add c2 node_iem_mero_c2
    pcs -f iem_cfg constraint order set consul-c1 node_iem_mero_c1
    pcs -f iem_cfg constraint order set consul-c2 node_iem_mero_c2

    pcs -f iem_cfg resource create node_iem_s3 ocf:seagate:iem_comp_ra path='node_iem_s3' filename='node_iem_s3' service="slapd" op monitor timeout=30s interval=30s
    pcs -f iem_cfg resource clone node_iem_s3 clone-max=2 clone-node-max=1
    pcs -f iem_cfg constraint location node_iem_s3-clone prefers ${lnode}=INFINITY
    pcs -f iem_cfg constraint location node_iem_s3-clone prefers ${rnode}=INFINITY
    pcs cluster cib-push iem_cfg
}

cleanup() {
    echo "Delete resources"
    resources=(
        io_path_health_c1
        io_path_health_c2
        mgmt_path_health_c1
        node_iem_mero_c1
        node_iem_mero_c2
        node_iem_s3
    )
    for r in ${resources[@]}; do
        pcs resource delete $r &
    done
    wait
}

ACTION=$1
ARGS=$2

$ACTION $ARGS
